# ğŸ¤Ÿ Tradutor de Libras com IA

Este projeto utiliza **Python + TensorFlow + MediaPipe + OpenCV** para reconhecer sinais de Libras a partir da cÃ¢mera em tempo real.  
A ideia Ã© treinar modelos de IA (MLP com landmarks e CNN com imagens) e usÃ¡-los para prever letras do alfabeto em Libras.  

Feito para a **Feira de CiÃªncias 2025** ğŸ§ªâœ¨

---

## ğŸ“‚ Estrutura do Projeto

```
hand_sign_project_with_runner/
â”‚â”€â”€ data/                # Onde ficam os datasets (X.npy e y.npy)
â”‚â”€â”€ debug/               # Imagens de debug geradas durante a coleta
â”‚â”€â”€ models/              # Modelos treinados (.h5)
â”‚â”€â”€ utils.py             # FunÃ§Ãµes de processamento (extraÃ§Ã£o de landmarks, etc.)
â”‚â”€â”€ train_landmarks_mlp.py  # Script para treinar modelo baseado em landmarks
â”‚â”€â”€ infer_realtime.py    # Script para rodar a cÃ¢mera em tempo real
â”‚â”€â”€ requirements.txt     # Lista de dependÃªncias do projeto
â”‚â”€â”€ README.md            # Este arquivo ğŸ˜ƒ
```

---

## âš™ï¸ InstalaÃ§Ã£o

Clone este repositÃ³rio e entre na pasta:

```bash
git clone https://github.com/seu-usuario/hand_sign_project_with_runner.git
cd hand_sign_project_with_runner
```

Crie um ambiente virtual (recomendado):

```bash
python -m venv venv
```

Ative o ambiente virtual:

- **Windows (PowerShell)**  
  ```bash
  venv\Scripts\Activate.ps1
  ```

- **Linux/Mac**  
  ```bash
  source venv/bin/activate
  ```

Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

---

## ğŸ§  Treinando o Modelo

Se ainda nÃ£o tiver o dataset (`X.npy` e `y.npy`):

```bash
python utils.py
```

Isso gera os arquivos em `data/`.

Depois, treine o modelo MLP com:

```bash
python train_landmarks_mlp.py
```

O modelo treinado serÃ¡ salvo em:

```
models/hand_sign_mlp.h5
```

---

## ğŸ“¸ Executando em Tempo Real

Para abrir a cÃ¢mera e comeÃ§ar a prever sinais:

```bash
python infer_realtime.py
```

- Pressione **Q** para sair.  
- O texto no canto superior esquerdo mostrarÃ¡ a letra reconhecida.  

---

## ğŸ›  Tecnologias Utilizadas

- [Python 3.11+](https://www.python.org/)  
- [TensorFlow/Keras](https://www.tensorflow.org/) â†’ treino e inferÃªncia do modelo  
- [MediaPipe](https://developers.google.com/mediapipe) â†’ detecÃ§Ã£o dos landmarks da mÃ£o  
- [OpenCV](https://opencv.org/) â†’ captura da cÃ¢mera e visualizaÃ§Ã£o  
- [NumPy](https://numpy.org/) â†’ manipulaÃ§Ã£o dos dados  

---

## ğŸ“Œ PrÃ³ximos Passos

- Aumentar o dataset (mais imagens para melhorar a acurÃ¡cia)  
- Adicionar novas letras e sinais da Libras  
- Criar uma interface mais amigÃ¡vel (GUI/Web)  
- Publicar em nuvem ou rodar em dispositivo mÃ³vel  

---

## ğŸ‘¨â€ğŸ’» Autores

- Projeto desenvolvido por **Bob/Giovanna Adriano de Carvalho** para a Bentotec Feira de CiÃªncias 2025.  

---
